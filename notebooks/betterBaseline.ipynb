{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 92834\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>13883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>11690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>11351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>8983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  artistID  weight\n",
       "0       0        45   13883\n",
       "1       0        46   11690\n",
       "2       0        47   11351\n",
       "3       0        48   10300\n",
       "4       0        49    8983"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "artists = pd.read_csv('dataset/remapped/artists.csv')\n",
    "tags = pd.read_csv('dataset/remapped/tags.csv')\n",
    "user_artists = pd.read_csv('dataset/remapped/user_artists.csv')\n",
    "user_tags = pd.read_csv('dataset/remapped/user_tags.csv')\n",
    "\n",
    "print(f\"Original length: {len(user_artists)}\")\n",
    "user_artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12133, 9719)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Assuming user_tags, tags, and artists DataFrames are already loaded\n",
    "\n",
    "# Get the distribution of tags for each artist\n",
    "artist_tag_distribution = (\n",
    "    user_tags.groupby(['artistID', 'tagID'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)  # Converts to wide format with tagIDs as columns\n",
    ")\n",
    "artist_tag_distribution.columns.name = None  # Remove column name for clarity\n",
    "artist_tag_distribution.reset_index(inplace=True)  # Make artistID a regular column\n",
    "\n",
    "artist_tag_distribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artistID</th>\n",
       "      <th>tagValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>weeabo jrock j-rock visual kei better than lad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>german seen live darkwave industrial german ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>black metal black metal norwegian black metal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>j-rock visual kei metal gothic japanese bazaro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>gothic gothic rock darkwave darkwave deathrock...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artistID                                           tagValue\n",
       "0         0  weeabo jrock j-rock visual kei better than lad...\n",
       "1         1  german seen live darkwave industrial german ge...\n",
       "2         2  black metal black metal norwegian black metal ...\n",
       "3         3  j-rock visual kei metal gothic japanese bazaro...\n",
       "4         4  gothic gothic rock darkwave darkwave deathrock..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 2. Build bag-of-words embeddings\n",
    "# Merge `user_tags` with `tags` to get the tag values\n",
    "user_tags_with_values = user_tags.merge(tags, how='left', left_on='tagID', right_on='tagID')\n",
    "\n",
    "# Combine all tag values for each artist\n",
    "artist_bow = user_tags_with_values.groupby('artistID')['tagValue'].apply(\n",
    "    lambda x: ' '.join(map(str, x))\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "artist_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 7592\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vectorize using CountVectorizer to build bag-of-words embeddings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(artist_bow['tagValue'])\n",
    "\n",
    "embedding_dim = len(vectorizer.get_feature_names_out())\n",
    "print(f\"Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with bag-of-words embeddings\n",
    "artist_embeddings = pd.DataFrame.sparse.from_spmatrix(\n",
    "    bow_matrix, columns=vectorizer.get_feature_names_out(), index=artist_bow['artistID']\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag distribution by artist:\n",
      "       artistID  0  1  2  3  4  5  6  7  8  ...  11935  11936  11937  11938  \\\n",
      "0             0  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "1             1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "2             2  0  0  0  3  0  0  0  0  0  ...      0      0      0      0   \n",
      "3             3  2  0  0  0  0  0  1  0  0  ...      0      0      0      0   \n",
      "4             4  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "...         ... .. .. .. .. .. .. .. .. ..  ...    ...    ...    ...    ...   \n",
      "12128     17623  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "12129     17625  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "12130     17626  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "12131     17627  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "12132     17630  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "\n",
      "       11939  11940  11941  11942  11943  11944  \n",
      "0          0      0      0      0      0      0  \n",
      "1          0      0      0      0      0      0  \n",
      "2          0      0      0      0      0      0  \n",
      "3          0      0      0      0      0      0  \n",
      "4          0      0      0      0      0      0  \n",
      "...      ...    ...    ...    ...    ...    ...  \n",
      "12128      0      0      0      0      0      0  \n",
      "12129      0      0      0      0      0      0  \n",
      "12130      0      0      0      0      0      0  \n",
      "12131      0      0      0      0      0      0  \n",
      "12132      0      0      0      0      0      0  \n",
      "\n",
      "[12133 rows x 9719 columns]\n",
      "\n",
      "Bag-of-Words Embeddings for artists:\n",
      "          00  007  00s  01  06  07  08  09  10  100  ...  zombie  zombieland  \\\n",
      "artistID                                             ...                       \n",
      "0          0    0    0   0   0   0   0   0   0    0  ...       0           0   \n",
      "1          0    0    0   0   0   0   0   0   0    0  ...       0           0   \n",
      "2          0    0    0   0   0   0   0   0   0    0  ...       0           0   \n",
      "3          0    0    0   0   0   0   0   0   0    0  ...       0           0   \n",
      "4          0    0    0   0   0   0   0   0   0    0  ...       0           0   \n",
      "...       ..  ...  ...  ..  ..  ..  ..  ..  ..  ...  ...     ...         ...   \n",
      "17623      0    0    0   0   0   0   0   0   0    0  ...       0           0   \n",
      "17625      0    0    0   0   0   0   0   0   0    0  ...       0           0   \n",
      "17626      0    0    0   0   0   0   0   0   0    0  ...       0           0   \n",
      "17627      0    0    0   0   0   0   0   0   0    0  ...       0           0   \n",
      "17630      0    0    0   0   0   0   0   0   0    0  ...       0           0   \n",
      "\n",
      "          zone  zoocore  zooey  zorn  zornish  ztt  zu  ärzte  \n",
      "artistID                                                       \n",
      "0            0        0      0     0        0    0   0      0  \n",
      "1            0        0      0     0        0    0   0      0  \n",
      "2            0        0      0     0        0    0   0      0  \n",
      "3            0        0      0     0        0    0   0      0  \n",
      "4            0        0      0     0        0    0   0      0  \n",
      "...        ...      ...    ...   ...      ...  ...  ..    ...  \n",
      "17623        0        0      0     0        0    0   0      0  \n",
      "17625        0        0      0     0        0    0   0      0  \n",
      "17626        0        0      0     0        0    0   0      0  \n",
      "17627        0        0      0     0        0    0   0      0  \n",
      "17630        0        0      0     0        0    0   0      0  \n",
      "\n",
      "[12133 rows x 7592 columns]\n",
      "\n",
      "Sparse matrix shape (artist_count x embedding_dim): (17632, 7592)\n"
     ]
    }
   ],
   "source": [
    "# 3. Build a sparse matrix of shape (artist_count, embedding_dim)\n",
    "# Ensure all artists have rows in the sparse matrix\n",
    "all_artists = artists[['id']].rename(columns={'id': 'artistID'})\n",
    "artist_embeddings_full = all_artists.merge(artist_embeddings, how='left', on='artistID').fillna(0)\n",
    "\n",
    "# Convert to sparse matrix\n",
    "embedding_sparse_matrix = csr_matrix(artist_embeddings_full.drop(columns=['artistID']).values)\n",
    "\n",
    "# Output results\n",
    "print(\"Tag distribution by artist:\")\n",
    "print(artist_tag_distribution)\n",
    "\n",
    "print(\"\\nBag-of-Words Embeddings for artists:\")\n",
    "print(artist_embeddings)\n",
    "\n",
    "print(\"\\nSparse matrix shape (artist_count x embedding_dim):\", embedding_sparse_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_name(artist_id):\n",
    "    return artists.loc[artists['id'] == artist_id, 'name'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar artists to artist 221:\n",
      "Artist: The Kinks, Similarity: 0.9475\n",
      "Artist: The Rolling Stones, Similarity: 0.9469\n",
      "Artist: The Who, Similarity: 0.9379\n",
      "Artist: The Moody Blues, Similarity: 0.9302\n",
      "Artist: The Animals, Similarity: 0.9216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_top_k_similar_artists(artist_id, embeddings, artist_index_map, k=5):\n",
    "    \"\"\"\n",
    "    Get the top K most similar artists to the given artist_id.\n",
    "\n",
    "    Parameters:\n",
    "    - artist_id (int): The ID of the artist to find similar artists for.\n",
    "    - embeddings (csr_matrix): The sparse matrix containing artist embeddings.\n",
    "    - artist_index_map (dict): A mapping of artist IDs to row indices in the embeddings matrix.\n",
    "    - k (int): The number of similar artists to return.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples: [(artist_id, similarity), ...] for the top K similar artists.\n",
    "    \"\"\"\n",
    "    # Ensure the artist ID is in the index map\n",
    "    if artist_id not in artist_index_map:\n",
    "        raise ValueError(f\"Artist ID {artist_id} not found in the embeddings.\")\n",
    "\n",
    "    # Get the index of the given artist\n",
    "    artist_idx = artist_index_map[artist_id]\n",
    "    \n",
    "    # Compute cosine similarity between the given artist and all others\n",
    "    artist_vector = embeddings[artist_idx]  # Sparse row for the given artist\n",
    "    similarities = cosine_similarity(artist_vector, embeddings).flatten()\n",
    "    \n",
    "    # Get the top K similar indices (excluding itself)\n",
    "    similar_indices = similarities.argsort()[::-1]  # Sort in descending order\n",
    "    top_k_indices = [idx for idx in similar_indices if idx != artist_idx][:k]\n",
    "    \n",
    "    # Map indices back to artist IDs and return their similarities\n",
    "    index_artist_map = {v: k for k, v in artist_index_map.items()}\n",
    "    top_k_artists = [(index_artist_map[idx], similarities[idx]) for idx in top_k_indices]\n",
    "\n",
    "    return top_k_artists\n",
    "\n",
    "# Create a mapping of artist IDs to their row indices in the embeddings matrix\n",
    "artist_index_map = {artist_id: idx for idx, artist_id in enumerate(artist_embeddings_full['artistID'])}\n",
    "\n",
    "# Example: Get the top 5 similar artists for a specific artist\n",
    "example_artist_id = 221\n",
    "top_k_similar_artists = get_top_k_similar_artists(example_artist_id, embedding_sparse_matrix, artist_index_map, k=5)\n",
    "\n",
    "# Output results\n",
    "print(f\"Top similar artists to artist {example_artist_id}:\")\n",
    "for artist_id, similarity in top_k_similar_artists:\n",
    "    print(f\"Artist: {get_artist_name(artist_id)}, Similarity: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_name(tag_id):\n",
    "    return tags.loc[tags['tagID'] == tag_id, 'tagValue'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested tags for artist 221:\n",
      "Tag: classic rock, Score: 187.8929\n",
      "Tag: rock, Score: 120.9716\n",
      "Tag: 60s, Score: 76.5420\n",
      "Tag: british, Score: 75.8443\n",
      "Tag: 70s, Score: 46.9514\n",
      "Tag: singer-songwriter, Score: 27.9086\n",
      "Tag: hard rock, Score: 24.3722\n",
      "Tag: pop, Score: 23.7341\n",
      "Tag: blues, Score: 16.8002\n",
      "Tag: rock and roll, Score: 13.9296\n"
     ]
    }
   ],
   "source": [
    "def suggest_tags_for_artist(artist_id, embeddings, artist_index_map, artist_tag_distribution, tag_names, k=5, top_tags=5):\n",
    "    \"\"\"\n",
    "    Suggest tags for a given artist based on similar artists' tags.\n",
    "\n",
    "    Parameters:\n",
    "    - artist_id (int): The ID of the artist to suggest tags for.\n",
    "    - embeddings (csr_matrix): The sparse matrix containing artist embeddings.\n",
    "    - artist_index_map (dict): A mapping of artist IDs to row indices in the embeddings matrix.\n",
    "    - artist_tag_distribution (pd.DataFrame): Tag distribution (artist x tags).\n",
    "    - tag_names (pd.DataFrame): Mapping of tag IDs to tag names.\n",
    "    - k (int): Number of similar artists to consider for tag suggestions.\n",
    "    - top_tags (int): Number of tags to suggest.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples: [(tag_id, tag_name, relevance_score), ...] for the suggested tags.\n",
    "    \"\"\"\n",
    "    # Ensure the artist ID is in the index map\n",
    "    if artist_id not in artist_index_map:\n",
    "        raise ValueError(f\"Artist ID {artist_id} not found in the embeddings.\")\n",
    "    \n",
    "    # Get the top K similar artists\n",
    "    similar_artists = get_top_k_similar_artists(artist_id, embeddings, artist_index_map, k=k)\n",
    "    \n",
    "    # Aggregate tag frequencies from similar artists\n",
    "    tag_scores = pd.Series(dtype=float)\n",
    "    for similar_artist_id, similarity in similar_artists:\n",
    "        if similar_artist_id in artist_tag_distribution['artistID'].values:\n",
    "            similar_tags = artist_tag_distribution.loc[\n",
    "                artist_tag_distribution['artistID'] == similar_artist_id\n",
    "            ].drop(columns=['artistID']).iloc[0]\n",
    "            # Weighted score for tags based on similarity\n",
    "            tag_scores = tag_scores.add(similar_tags * similarity, fill_value=0)\n",
    "    \n",
    "    # Sort tags by their weighted scores\n",
    "    suggested_tags = tag_scores.sort_values(ascending=False).head(top_tags)\n",
    "    \n",
    "    return suggested_tags.items()\n",
    "\n",
    "suggested_tags = suggest_tags_for_artist(\n",
    "    example_artist_id, embedding_sparse_matrix, artist_index_map, artist_tag_distribution, tags, k=10, top_tags=10\n",
    ")\n",
    "\n",
    "# Output results\n",
    "print(f\"Suggested tags for artist {example_artist_id}:\")\n",
    "for tag_id, score in suggested_tags:\n",
    "    tag_name = get_tag_name(tag_id)\n",
    "    print(f\"Tag: {tag_name}, Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance after reduction: 0.9778\n",
      "Reduced embedding for artist ID 221:\n",
      "[ 1.99156984e+02 -8.09605989e+00 -2.07340201e+01 -7.98043906e+01\n",
      "  2.24498500e+00 -3.77623769e+01 -1.66087292e+01  1.06037363e+01\n",
      "  3.80467758e+00 -8.15879906e+00  3.06396838e+01 -4.91644535e+01\n",
      "  2.33870321e+01  1.20293662e+01 -2.07027584e+01 -3.21609714e+01\n",
      " -8.52783568e+00 -6.54970041e+00 -3.60944579e+00 -6.10564733e+00\n",
      " -9.79286442e+00  5.88707991e+00 -6.97626061e+00 -4.35303494e+00\n",
      "  8.36896858e+00 -5.73532328e+00 -4.19163054e-01  7.72675663e+00\n",
      "  1.28197036e+00 -1.53928446e+00 -1.45813747e+00  5.10941555e+00\n",
      "  2.70427719e+00 -5.33667038e+00 -3.02804464e-01  4.94388017e+00\n",
      " -3.98026503e+00  4.29310320e+00 -1.01953643e+01  8.30274162e+00\n",
      "  6.14296966e+00  3.74565172e+00  5.91632560e-01 -4.52687227e+00\n",
      "  6.86095562e+00 -9.57254355e+00 -1.98814995e+00 -1.80982428e+00\n",
      "  1.82833230e-01  5.09742498e-01 -1.27014056e-01 -3.91763293e+00\n",
      "  7.99440808e-01  1.53655097e+00  2.78649642e+00 -1.23896311e+00\n",
      "  1.17565523e-01  1.31919504e+00  1.33741295e+00 -4.55665870e-01\n",
      "  4.48995987e-01 -1.73271102e+00  2.93211880e-01  2.39081896e+00\n",
      " -1.45159199e-01  5.95771930e-01 -4.93903153e-02 -3.29145320e-02\n",
      " -3.25904865e-01  2.39800087e-01  4.37045835e-01 -9.75751510e-02\n",
      " -7.29607209e-01  2.29040797e-02  1.16881810e+00  8.30507644e-01\n",
      "  5.51053705e-01  1.29908014e+00  4.35852783e-01 -1.11623784e+00\n",
      "  6.40003358e-01  2.92835058e+00 -8.05662542e-01 -8.42063938e-01\n",
      " -1.37104855e+00 -3.04840618e-01  2.08700840e+00 -3.89399456e-01\n",
      " -5.68721250e-01 -4.29219768e-01  3.06507564e-01  9.55193869e-01\n",
      " -5.65157814e-01  4.52771564e-01 -8.84027852e-01 -6.08886539e-01\n",
      " -2.23248135e+00  3.14040898e-04  7.31774647e-01  1.46645772e-01\n",
      " -4.42625432e-01  1.73132238e+00 -5.94273661e-01  1.47434144e+00\n",
      "  1.81623576e-01  9.67033218e-02 -1.28258180e+00  8.73917419e-02\n",
      " -2.32258055e-01 -7.93855698e-01 -2.00147522e-01 -8.00607833e-02\n",
      "  3.17115739e-01 -1.06796102e+00 -1.29950101e+00  5.17597779e-01\n",
      "  8.85569317e-01  3.94366449e-01  2.16004219e-01  2.44364864e-01\n",
      "  1.22869040e+00 -5.10658161e-02  8.95862013e-01  7.90835499e-01\n",
      " -2.53528187e-01 -2.51925846e-01  4.47365653e-01 -5.72760994e-01\n",
      " -3.15048943e-02  6.02077044e-01 -1.64427654e+00 -6.12257475e-01\n",
      "  8.47058156e-01 -5.22525379e-01 -1.10825402e+00  7.11976102e-01\n",
      "  1.65738756e+00  4.19409844e-01 -2.99784636e-01 -4.30845896e-01\n",
      " -7.35092980e-01  5.08016132e-01 -9.13519036e-02  1.32944161e+00\n",
      "  7.10151047e-01 -9.37812055e-01  6.56254964e-01  5.45989443e-01\n",
      " -7.29538318e-01 -1.09738955e-01  8.06995709e-01  1.84348435e-01\n",
      "  9.31704355e-01  3.80106249e-02 -5.70297861e-01  1.53457970e+00\n",
      "  1.01602179e-01  1.14245445e-01  6.90361725e-01  9.17486018e-01\n",
      " -4.36219872e-01 -9.77700214e-01 -6.36582631e-01 -6.38781839e-02\n",
      " -3.96783720e-01  2.34044551e-01 -1.08941968e+00 -1.36446926e-02\n",
      "  7.26468983e-01 -8.50063154e-01 -9.86586621e-01  6.96836085e-01\n",
      "  2.89119058e-01 -6.32992447e-01  7.37681480e-01  6.29365544e-01\n",
      "  1.07385649e+00  2.20579164e-01 -3.10208187e-01 -1.07104159e+00\n",
      "  5.09591143e-01 -1.11328821e-01 -7.39053160e-01  2.38192083e-01\n",
      "  2.20182725e-01  5.06439492e-01  2.29080306e-01 -6.70896788e-01\n",
      " -7.58136816e-01 -2.07742853e-01 -2.91616763e-01 -2.86263836e-01\n",
      " -9.48609439e-01  6.28068018e-01  3.29048975e-02 -1.14408347e-01\n",
      "  1.06355407e-01 -1.97247093e-01 -1.31012424e+00 -8.89095773e-02]\n",
      "Shape of reduced embedding matrix: (17632, 200)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def reduce_embedding_dimension(embeddings, target_dim=200):\n",
    "    \"\"\"\n",
    "    Reduce the dimension of embeddings to a specified size using Truncated SVD.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings (csr_matrix): Sparse matrix of artist embeddings.\n",
    "    - target_dim (int): The desired number of dimensions for the reduced embeddings.\n",
    "\n",
    "    Returns:\n",
    "    - reduced_embeddings (np.ndarray): Dense array of reduced embeddings.\n",
    "    \"\"\"\n",
    "    # Initialize Truncated SVD\n",
    "    svd = TruncatedSVD(n_components=target_dim, random_state=42)\n",
    "    \n",
    "    # Fit and transform the sparse matrix\n",
    "    reduced_embeddings = svd.fit_transform(embeddings)\n",
    "    \n",
    "    # Explained variance ratio to ensure the quality of reduction\n",
    "    explained_variance = np.sum(svd.explained_variance_ratio_)\n",
    "    print(f\"Explained variance after reduction: {explained_variance:.4f}\")\n",
    "    \n",
    "    return reduced_embeddings\n",
    "\n",
    "\n",
    "# Reduce the embedding space to 200 dimensions\n",
    "reduced_embeddings = reduce_embedding_dimension(embedding_sparse_matrix, target_dim=200)\n",
    "\n",
    "# Example: Get reduced embedding for artist ID 2\n",
    "artist_idx = artist_index_map[example_artist_id]\n",
    "artist_reduced_embedding = reduced_embeddings[artist_idx]\n",
    "\n",
    "# Output results\n",
    "print(f\"Reduced embedding for artist ID {example_artist_id}:\")\n",
    "print(artist_reduced_embedding)\n",
    "print(f\"Shape of reduced embedding matrix: {reduced_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix shape: (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Create a sparse matrix for user-artist interactions\n",
    "user_artist_matrix = coo_matrix(\n",
    "    (user_artists['weight'], (user_artists['userID'], user_artists['artistID']))\n",
    ")\n",
    "\n",
    "# Output the shape of the matrix\n",
    "print(f\"Sparse matrix shape: {user_artist_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions matrix shape: (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "from lightfm.data import Dataset\n",
    "\n",
    "# Initialize the Dataset object\n",
    "dataset = Dataset(user_identity_features=False, item_identity_features=False)\n",
    "\n",
    "# Fit the dataset with users and items\n",
    "# Specify the number of users and items based on the user_artist_matrix\n",
    "num_users, num_artists = user_artist_matrix.shape\n",
    "dataset.fit(\n",
    "    range(num_users),  # User IDs\n",
    "    range(num_artists)  # Artist IDs\n",
    ")\n",
    "\n",
    "# Build interactions and weights matrices\n",
    "(interactions, weights) = dataset.build_interactions(\n",
    "    [(row['userID'], row['artistID'], row['weight']) for _, row in user_artists.iterrows()]\n",
    ")\n",
    "\n",
    "# Output the shape of the interactions matrix\n",
    "print(f\"Interactions matrix shape: {interactions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training interactions: 74267\n",
      "Testing interactions: 18567\n"
     ]
    }
   ],
   "source": [
    "from lightfm.cross_validation import random_train_test_split\n",
    "\n",
    "# Split the interactions into training and testing datasets\n",
    "train, test = random_train_test_split(interactions, test_percentage=0.2, random_state=42)\n",
    "trainweighted, testweighted = random_train_test_split(weights, test_percentage=0.2, random_state=42)\n",
    "\n",
    "# Output the number of interactions in train and test\n",
    "print(f\"Training interactions: {train.getnnz()}\")\n",
    "print(f\"Testing interactions: {test.getnnz()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item features shape: (17632, 7592)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Ensure the embeddings have the same number of items as in the dataset\n",
    "item_features = csr_matrix(embedding_sparse_matrix)\n",
    "\n",
    "# Check the shape of the item_features\n",
    "print(f\"Item features shape: {item_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "\n",
    "# Initialize the LightFM model\n",
    "embedding_dim = embedding_sparse_matrix.shape[1]\n",
    "model = LightFM(no_components=20, loss='warp')\n",
    "\n",
    "# Train the model for one epoch\n",
    "model.fit(train, item_features=item_features, epochs=1, num_threads=4)\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitModels(epochs, no_components, weights,item_features, train):\n",
    "    models = {}\n",
    "\n",
    "    number_of_models = len(epochs) * len(no_components) * 4\n",
    "    i = 0\n",
    "    for epoch in epochs:\n",
    "        for component in no_components:\n",
    "            # Both\n",
    "            print(f\"Training model with {component} components and {epoch} epochs ({i}/{number_of_models})\")\n",
    "            model = LightFM(no_components=component, loss='warp')\n",
    "            model.fit(weights,train, item_features=item_features, epochs=epoch, num_threads=4,verbose=True)\n",
    "            models[(epoch, component,i%4)] = model\n",
    "            i += 1\n",
    "\n",
    "            # Only item features\n",
    "            print(f\"Training model with {component} components and {epoch} epochs ({i}/{number_of_models})\")\n",
    "            model = LightFM(no_components=component, loss='warp')\n",
    "            model.fit(train, item_features=item_features, epochs=epoch, num_threads=4,verbose=True)\n",
    "            models[(epoch, component, i%4)] = model\n",
    "            i += 1\n",
    "\n",
    "            # Only sample weights\n",
    "            print(f\"Training model with {component} components and {epoch} epochs ({i}/{number_of_models})\")\n",
    "            model = LightFM(no_components=component, loss='warp')\n",
    "            model.fit(weights,train, epochs=epoch, num_threads=4,verbose=True)\n",
    "            models[(epoch, component, i%4)] = model\n",
    "            i += 1\n",
    "\n",
    "            # No item features or sample weights\n",
    "            print(f\"Training model with {component} components and {epoch} epochs ({i}/{number_of_models})\")\n",
    "            model = LightFM(no_components=component, loss='warp')\n",
    "            model.fit(train, epochs=epoch, num_threads=4,verbose=True)\n",
    "            models[(epoch, component,i%4)] = model\n",
    "            i += 1\n",
    "\n",
    "\n",
    "    return models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 5 components and 1 epochs (0/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:05<00:00,  5.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 5 components and 1 epochs (1/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:02<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 5 components and 1 epochs (2/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:02<00:00,  2.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 5 components and 1 epochs (3/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 10 components and 1 epochs (4/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:10<00:00, 10.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 10 components and 1 epochs (5/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:04<00:00,  4.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 10 components and 1 epochs (6/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:04<00:00,  4.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with 10 components and 1 epochs (7/8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:02<00:00,  2.44s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = [1]\n",
    "no_components = [5,10]\n",
    "\n",
    "models = fitModels(epochs, no_components, weights, item_features, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "def evaluateModel(model, test, train, item_features):\n",
    "\n",
    "    # Compute and print the AUC score\n",
    "    train_auc = auc_score(model, train, item_features=item_features).mean()\n",
    "    test_auc = auc_score(model, test, train_interactions=train, item_features=item_features).mean()\n",
    "\n",
    "    return train_auc, test_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 5, 0): <lightfm.lightfm.LightFM object at 0x7fe990c497f0>, (1, 5, 1): <lightfm.lightfm.LightFM object at 0x7fe9938e42f0>, (1, 5, 2): <lightfm.lightfm.LightFM object at 0x7fe9d94c3800>, (1, 5, 3): <lightfm.lightfm.LightFM object at 0x7fe9da8eb2f0>, (1, 10, 0): <lightfm.lightfm.LightFM object at 0x7fe9938e4170>, (1, 10, 1): <lightfm.lightfm.LightFM object at 0x7fe9da9b3b30>, (1, 10, 2): <lightfm.lightfm.LightFM object at 0x7fe9d9d49af0>, (1, 10, 3): <lightfm.lightfm.LightFM object at 0x7fe9da8f3bc0>}\n"
     ]
    }
   ],
   "source": [
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incorrect number of features in item_features",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m futures \u001b[38;5;241m=\u001b[39m [executor\u001b[38;5;241m.\u001b[39msubmit(evaluate_model_parallel, key) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m models]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m future \u001b[38;5;129;01min\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mas_completed(futures):\n\u001b[0;32m---> 11\u001b[0m     key, train_auc, test_auc \u001b[38;5;241m=\u001b[39m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - Train AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Test AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib64/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/usr/lib64/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn[35], line 4\u001b[0m, in \u001b[0;36mevaluate_model_parallel\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate_model_parallel\u001b[39m(key):\n\u001b[0;32m----> 4\u001b[0m     train_auc, test_auc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluateModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m key, train_auc, test_auc\n",
      "Cell \u001b[0;32mIn[32], line 6\u001b[0m, in \u001b[0;36mevaluateModel\u001b[0;34m(model, test, train, item_features)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluateModel\u001b[39m(model, test, train, item_features):\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Compute and print the AUC score\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     train_auc \u001b[38;5;241m=\u001b[39m \u001b[43mauc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem_features\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      7\u001b[0m     test_auc \u001b[38;5;241m=\u001b[39m auc_score(model, test, train_interactions\u001b[38;5;241m=\u001b[39mtrain, item_features\u001b[38;5;241m=\u001b[39mitem_features)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_auc, test_auc\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/lightfm/evaluation.py:224\u001b[0m, in \u001b[0;36mauc_score\u001b[0;34m(model, test_interactions, train_interactions, user_features, item_features, preserve_rows, num_threads, check_intersections)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_threads \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of threads must be 1 or larger.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 224\u001b[0m ranks \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_rank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_interactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_interactions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_interactions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mitem_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_intersections\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_intersections\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(ranks\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    235\u001b[0m auc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(ranks\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/lightfm/lightfm.py:954\u001b[0m, in \u001b[0;36mLightFM.predict_rank\u001b[0;34m(self, test_interactions, train_interactions, item_features, user_features, num_threads, check_intersections)\u001b[0m\n\u001b[1;32m    949\u001b[0m (user_features, item_features) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_feature_matrices(\n\u001b[1;32m    950\u001b[0m     n_users, n_items, user_features, item_features\n\u001b[1;32m    951\u001b[0m )\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m item_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 954\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect number of features in item_features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m user_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_embeddings\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    957\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect number of features in user_features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Incorrect number of features in item_features"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def evaluate_model_parallel(key):\n",
    "    train_auc, test_auc = evaluateModel(models[key], test, train, item_features)\n",
    "    return key, train_auc, test_auc\n",
    "\n",
    "# Evaluate all models in parallel\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    futures = [executor.submit(evaluate_model_parallel, key) for key in models]\n",
    "    for future in concurrent.futures.as_completed(futures):\n",
    "        key, train_auc, test_auc = future.result()\n",
    "        print(f\"Model {key} - Train AUC: {train_auc:.4f}, Test AUC: {test_auc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
