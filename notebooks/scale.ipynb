{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 92834\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>pictureURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>MALICE MIZER</td>\n",
       "      <td>http://www.last.fm/music/MALICE+MIZER</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/10808.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Diary of Dreams</td>\n",
       "      <td>http://www.last.fm/music/Diary+of+Dreams</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/3052066.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Carpathian Forest</td>\n",
       "      <td>http://www.last.fm/music/Carpathian+Forest</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/40222717...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Moi dix Mois</td>\n",
       "      <td>http://www.last.fm/music/Moi+dix+Mois</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/54697835...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Bella Morte</td>\n",
       "      <td>http://www.last.fm/music/Bella+Morte</td>\n",
       "      <td>http://userserve-ak.last.fm/serve/252/14789013...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               name                                         url  \\\n",
       "0   0       MALICE MIZER       http://www.last.fm/music/MALICE+MIZER   \n",
       "1   1    Diary of Dreams    http://www.last.fm/music/Diary+of+Dreams   \n",
       "2   2  Carpathian Forest  http://www.last.fm/music/Carpathian+Forest   \n",
       "3   3       Moi dix Mois       http://www.last.fm/music/Moi+dix+Mois   \n",
       "4   4        Bella Morte        http://www.last.fm/music/Bella+Morte   \n",
       "\n",
       "                                          pictureURL  \n",
       "0    http://userserve-ak.last.fm/serve/252/10808.jpg  \n",
       "1  http://userserve-ak.last.fm/serve/252/3052066.jpg  \n",
       "2  http://userserve-ak.last.fm/serve/252/40222717...  \n",
       "3  http://userserve-ak.last.fm/serve/252/54697835...  \n",
       "4  http://userserve-ak.last.fm/serve/252/14789013...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "artists = pd.read_csv('dataset/remapped/artists.csv')\n",
    "tags = pd.read_csv('dataset/remapped/tags.csv')\n",
    "user_artists = pd.read_csv('dataset/remapped/user_artists.csv')\n",
    "user_tags = pd.read_csv('dataset/remapped/user_tags.csv')\n",
    "\n",
    "print(f\"Original length: {len(user_artists)}\")\n",
    "artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92834 92834\n",
      "<COOrdinate sparse matrix of dtype 'float32'\n",
      "\twith 92834 stored elements and shape (1892, 17632)>\n",
      "  Coords\tValues\n",
      "  (0, 0)\t13883.0\n",
      "  (0, 1)\t11690.0\n",
      "  (0, 2)\t11351.0\n",
      "  (0, 3)\t10300.0\n",
      "  (0, 4)\t8983.0\n",
      "  (0, 5)\t6152.0\n",
      "  (0, 6)\t5955.0\n",
      "  (0, 7)\t4616.0\n",
      "  (0, 8)\t4337.0\n",
      "  (0, 9)\t4147.0\n",
      "  (0, 10)\t3923.0\n",
      "  (0, 11)\t3782.0\n",
      "  (0, 12)\t3735.0\n",
      "  (0, 13)\t3644.0\n",
      "  (0, 14)\t3579.0\n",
      "  (0, 15)\t3312.0\n",
      "  (0, 16)\t3301.0\n",
      "  (0, 17)\t2927.0\n",
      "  (0, 18)\t2720.0\n",
      "  (0, 19)\t2686.0\n",
      "  (0, 20)\t2654.0\n",
      "  (0, 21)\t2619.0\n",
      "  (0, 22)\t2584.0\n",
      "  (0, 23)\t2547.0\n",
      "  (0, 24)\t2397.0\n",
      "  :\t:\n",
      "  (1891, 7993)\t284.0\n",
      "  (1891, 7995)\t650.0\n",
      "  (1891, 7996)\t456.0\n",
      "  (1891, 7997)\t1068.0\n",
      "  (1891, 7999)\t626.0\n",
      "  (1891, 8000)\t613.0\n",
      "  (1891, 8005)\t655.0\n",
      "  (1891, 8017)\t640.0\n",
      "  (1891, 8174)\t232.0\n",
      "  (1891, 8178)\t429.0\n",
      "  (1891, 8180)\t607.0\n",
      "  (1891, 8182)\t724.0\n",
      "  (1891, 9413)\t793.0\n",
      "  (1891, 9601)\t228.0\n",
      "  (1891, 17624)\t705.0\n",
      "  (1891, 12989)\t278.0\n",
      "  (1891, 12991)\t346.0\n",
      "  (1891, 17625)\t535.0\n",
      "  (1891, 15542)\t443.0\n",
      "  (1891, 17626)\t758.0\n",
      "  (1891, 17627)\t337.0\n",
      "  (1891, 17628)\t297.0\n",
      "  (1891, 17629)\t281.0\n",
      "  (1891, 17630)\t280.0\n",
      "  (1891, 17631)\t263.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from lightfm.data import Dataset\n",
    "from lightfm import LightFM\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Create interactions with normalized weights\n",
    "dataset = Dataset()\n",
    "dataset.fit(users=user_artists['userID'].unique(),\n",
    "            items=user_artists['artistID'].unique())\n",
    "\n",
    "(interactions, weights) = dataset.build_interactions(\n",
    "    zip(user_artists['userID'], user_artists['artistID'], user_artists['weight'])\n",
    ")\n",
    "\n",
    "# Recreate sparse weight matrix directly from the weights\n",
    "weights_sparse = coo_matrix(\n",
    "    (weights.data, (weights.row, weights.col)),\n",
    "    shape=interactions.shape\n",
    ")\n",
    "\n",
    "assert interactions.shape == weights_sparse.shape, \"Shapes of interactions and weights must match!\"\n",
    "assert interactions.nnz == weights_sparse.nnz, \"Number of non-zero elements must match!\"\n",
    "\n",
    "print(interactions.nnz, weights_sparse.nnz)\n",
    "\n",
    "\n",
    "print(weights_sparse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split into train and test\n",
    "train, test = random_train_test_split(interactions, test_percentage=0.2, random_state=42)\n",
    "train_weights, test_weights = random_train_test_split(weights_sparse, test_percentage=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f8ff6f95fd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Initialize the model\n",
    "model = LightFM(loss='warp', item_alpha=1e-6, user_alpha=1e-6)\n",
    "\n",
    "# Normalizzeweights\n",
    "\n",
    "\n",
    "# Train with weights\n",
    "EPOCHS = 10\n",
    "THREADS = 4\n",
    "model.fit(train, sample_weight=train_weights, epochs=EPOCHS, num_threads=THREADS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightfm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m precision_at_k, recall_at_k\n\u001b[0;32m----> 2\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_at_k(\u001b[43mmodel\u001b[49m,train, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_threads\u001b[38;5;241m=\u001b[39mTHREADS)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      3\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_at_k(model,train, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_threads\u001b[38;5;241m=\u001b[39mTHREADS)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      5\u001b[0m precision_test \u001b[38;5;241m=\u001b[39m precision_at_k(model,test, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, num_threads\u001b[38;5;241m=\u001b[39mTHREADS)\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "precision = precision_at_k(model,train, k=10, num_threads=THREADS).mean()\n",
    "recall = recall_at_k(model,train, k=10, num_threads=THREADS).mean()\n",
    "\n",
    "precision_test = precision_at_k(model,test, k=10, num_threads=THREADS).mean()\n",
    "recall_test = recall_at_k(model,test, k=10, num_threads=THREADS).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain precision@10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mprecision\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain recall@10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest precision@10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprecision_test\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precision' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Train precision@10: {precision}\")\n",
    "print(f\"Train recall@10: {recall}\")\n",
    "print(f\"Test precision@10: {precision_test}\")\n",
    "print(f\"Test recall@10: {recall_test}\")\n",
    "precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# extract item similarities\n",
    "item_biases, item_embeddings = model.get_item_representations()\n",
    "\n",
    "item_to_item = pd.DataFrame(cosine_similarity(item_embeddings))\n",
    "\n",
    "rhcp_id = artists[artists['name'] == 'Red Hot Chili Peppers']['id'].values[0]\n",
    "similar = item_to_item[rhcp_id].sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Red Hot Chili Peppers', \"2 Many DJ's\", 'Dealema', 'Plies',\n",
       "       'George Jones', 'The Psychedelic Furs', 'Kate Voegele', 'Common',\n",
       "       'Dulce María', 'Coconut Records', 'Astor Piazzolla',\n",
       "       'The Spill Canvas', 'Tequila Baby', 'Velcra', 'Skeletal Family',\n",
       "       'Laith Al-Deen', 'Masacre', 'Fjordne', 'Animal Collective',\n",
       "       'Tynisha Keli'], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the names of the top 10 similar artists\n",
    "similar_artists = artists.set_index('id').loc[similar.index]['name'].values\n",
    "\n",
    "similar_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge user_tags with tags to get artistID, tagID, and count tag occurrences\n",
    "tag_data = pd.merge(user_tags, tags, on='tagID')\n",
    "tag_data = tag_data.groupby(['artistID', 'tagID']).size().reset_index(name='count')\n",
    "\n",
    "# Map artistID and tagID to consecutive indices based on the dataset\n",
    "artist_mapping = {artist: idx for idx, artist in enumerate(user_artists['artistID'].unique())}\n",
    "tag_mapping = {tag: idx for idx, tag in enumerate(tags['tagID'].unique())}\n",
    "\n",
    "# Map artistID and tagID to indices\n",
    "tag_data['artist_idx'] = tag_data['artistID'].map(artist_mapping)\n",
    "tag_data['tag_idx'] = tag_data['tagID'].map(tag_mapping)\n",
    "\n",
    "# Build the sparse matrix (artist x tag)\n",
    "item_features = coo_matrix(\n",
    "    (tag_data['count'], (tag_data['artist_idx'], tag_data['tag_idx'])),\n",
    "    shape=(len(artist_mapping), len(tag_mapping))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(108437, 5) (1892, 17632) (11946, 2) (17632, 4) (17632, 11946)\n"
     ]
    }
   ],
   "source": [
    "print(tag_data.shape, interactions.shape, tags.shape, artists.shape, item_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7ff0adbabb00>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss='warp', item_alpha=1e-6, user_alpha=1e-6)\n",
    "\n",
    "# Train with item features\n",
    "model.fit(train,\n",
    "          item_features=item_features,\n",
    "          sample_weight=train_weights,\n",
    "          epochs=1,\n",
    "          num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "precision = precision_at_k(model, train, item_features=item_features, k=10, num_threads=4).mean()\n",
    "recall = recall_at_k(model, train, item_features=item_features, k=10, num_threads=8).mean()\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1892, 17632) (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 20/20 [00:34<00:00,  1.71s/it]\n",
      "Epoch: 100%|██████████| 20/20 [01:52<00:00,  5.61s/it]\n",
      "Epoch: 100%|██████████| 20/20 [00:42<00:00,  2.13s/it]\n",
      "Epoch: 100%|██████████| 20/20 [02:06<00:00,  6.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x7f79e73f4440>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a bigger model with 30 components\n",
    "# Fit partially to display progress\n",
    "\n",
    "model_base = LightFM(loss='warp',item_alpha=1e-6, user_alpha=1e-6, no_components=10)\n",
    "model_features = LightFM(loss='warp', item_alpha=1e-6, user_alpha=1e-6, no_components=30)\n",
    "model_noweights = LightFM(loss='warp', item_alpha=1e-6, user_alpha=1e-6, no_components=30)\n",
    "model_noweights_features = LightFM(loss='warp', item_alpha=1e-6, user_alpha=1e-6, no_components=30)\n",
    "\n",
    "EPOCHS = 20\n",
    "THREADS = 4\n",
    "\n",
    "model_base.fit(train, sample_weight=train_weights, epochs=EPOCHS, num_threads=THREADS,verbose=True)\n",
    "model_features.fit(train, item_features=item_features, sample_weight=train_weights, epochs=EPOCHS, num_threads=THREADS,verbose=True)\n",
    "model_noweights.fit(train, epochs=EPOCHS, num_threads=THREADS,verbose=True)\n",
    "model_noweights_features.fit(train, item_features=item_features, epochs=EPOCHS, num_threads=THREADS,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision and AUC score\n",
    "from lightfm.evaluation import precision_at_k, auc_score\n",
    "\n",
    "precision_base = precision_at_k(model_base, test, train_interactions=train, k=10, num_threads=THREADS).mean()\n",
    "auc_base = auc_score(model_base, test, train_interactions=train, num_threads=THREADS).mean()\n",
    "\n",
    "precision_features = precision_at_k(model_features, test, item_features=item_features, train_interactions=train, k=10, num_threads=THREADS).mean()\n",
    "auc_features = auc_score(model_features, test, item_features=item_features, train_interactions=train, num_threads=THREADS).mean()\n",
    "\n",
    "precision_noweights = precision_at_k(model_noweights, test, train_interactions=train, k=10, num_threads=THREADS).mean()\n",
    "auc_noweights = auc_score(model_noweights, test, train_interactions=train, num_threads=THREADS).mean()\n",
    "\n",
    "precision_noweights_features = precision_at_k(model_noweights_features, test, item_features=item_features, train_interactions=train, k=10, num_threads=THREADS).mean()\n",
    "auc_noweights_features = auc_score(model_noweights_features, test, item_features=item_features, train_interactions=train, num_threads=THREADS).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base model - Precision@10: 0.1335991621017456, AUC: 0.8645904064178467\n",
      "Features model - Precision@10: 0.014088250696659088, AUC: 0.5344148874282837\n",
      "No weights model - Precision@10: 0.1514088213443756, AUC: 0.8739895820617676\n",
      "No weights, features model - Precision@10: 0.01105794869363308, AUC: 0.5017257928848267\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(f\"Base model - Precision@10: {precision_base}, AUC: {auc_base}\")\n",
    "print(f\"Features model - Precision@10: {precision_features}, AUC: {auc_features}\")\n",
    "print(f\"No weights model - Precision@10: {precision_noweights}, AUC: {auc_noweights}\")\n",
    "print(f\"No weights, features model - Precision@10: {precision_noweights_features}, AUC: {auc_noweights_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag: rock\n",
      "Filtered out 11720 tags with less than 100 occurrences\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([209,  57,  65,  39,  17,  74, 186, 106, 190,  63])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_similar_tag_ids(model,tag_id,k=3, user_tags=None,min_count=10):\n",
    "\n",
    "    tag_embeddings = (model.item_embeddings.T / np.linalg.norm(model.item_embeddings, axis=1)).T\n",
    "\n",
    "    query_embedding = tag_embeddings[tag_id]\n",
    "    similarity = np.dot(tag_embeddings, query_embedding)\n",
    "\n",
    "    # Filter out tags with low counts\n",
    "    if user_tags is not None:\n",
    "        tag_counts = user_tags.groupby('tagID').size()\n",
    "        tag_counts = tag_counts[tag_counts >= min_count]\n",
    "        print(f\"Filtered out {len(tags) - len(tag_counts)} tags with less than {min_count} occurrences\")\n",
    "        similarity = similarity[tag_counts.index]\n",
    "\n",
    "    most_similar = np.argsort(-similarity)[1:k+1]\n",
    "\n",
    "    return most_similar\n",
    "\n",
    "tag_id = 72\n",
    "# Print tag name\n",
    "tag_name = tags[tags['tagID'] == tag_id]['tagValue'].values[0]\n",
    "print(f\"Tag: {tag_name}\")\n",
    "similar_tag_ids = get_similar_tag_ids(model_features, tag_id, user_tags=user_tags,k=10, min_count=100)\n",
    "similar_tag_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00s', 'halbischt', 'abstract', 'gregorian chant', 'electronic',\n",
       "       'psychedelic rock', 'electronica', 'kizomba', 'instrumental',\n",
       "       'mille plateaux'], dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the similar tags\n",
    "similar_tags = tags.set_index('tagID').loc[similar_tag_ids]['tagValue'].values\n",
    "similar_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    tagID tagValue\n",
      "72     72     rock\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17632, 30)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.nnz\n",
    "\n",
    "# Get features for the rock column\n",
    "rock_idx = tag_mapping[72]\n",
    "print(tags[tags['tagID'] == rock_idx])\n",
    "\n",
    "item_biases, item_embeddings = model_features.get_item_representations(features=item_features)\n",
    "\n",
    "item_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'getcol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[130], line 27\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28mprint\u001b[39m(item_embeddings\u001b[38;5;241m.\u001b[39mshape, query_embedding)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m most_similar\n\u001b[0;32m---> 27\u001b[0m similar_artists \u001b[38;5;241m=\u001b[39m \u001b[43mget_similar_artists_to_tag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_artists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_artists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m similar_artists\n",
      "Cell \u001b[0;32mIn[130], line 6\u001b[0m, in \u001b[0;36mget_similar_artists_to_tag\u001b[0;34m(model, tag_id, item_features, k, user_artists, min_count)\u001b[0m\n\u001b[1;32m      4\u001b[0m tag_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mitem_embeddings\n\u001b[1;32m      5\u001b[0m item_biases, item_embeddings \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_item_representations(features\u001b[38;5;241m=\u001b[39mitem_features)\n\u001b[0;32m----> 6\u001b[0m query_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mitem_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetcol\u001b[49m(tag_mapping[tag_id])\u001b[38;5;241m.\u001b[39mtoarray()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarity\u001b[39;00m\n\u001b[1;32m      9\u001b[0m similarity \u001b[38;5;241m=\u001b[39m cosine_similarity(item_embeddings\u001b[38;5;241m.\u001b[39mT, [query_embedding])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'getcol'"
     ]
    }
   ],
   "source": [
    "# Now, get the artists most similar to a specific tag\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def get_similar_artists_to_tag(model, tag_id, item_features, k=3, user_artists=None, min_count=100):\n",
    "    tag_embeddings = model.item_embeddings\n",
    "    item_biases, item_embeddings = model.get_item_representations(features=item_features)\n",
    "    query_embedding = item_embeddings.getcol(tag_mapping[tag_id]).toarray().flatten()\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = cosine_similarity(item_embeddings.T, [query_embedding])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Filter out artists with low counts\n",
    "    if user_artists is not None:\n",
    "        artist_counts = user_artists.groupby('artistID').size()\n",
    "        artist_counts = artist_counts[artist_counts >= min_count]\n",
    "        print(f\"Filtered out {len(artists) - len(artist_counts)} artists with less than {min_count} occurrences\")\n",
    "        item_embeddings = item_embeddings[artist_counts.index]\n",
    "\n",
    "        print(item_embeddings.shape, query_embedding)\n",
    "\n",
    "    \n",
    "    return most_similar\n",
    "\n",
    "similar_artists = get_similar_artists_to_tag(model_features, tag_id, item_features, k=10, user_artists=user_artists, min_count=10)\n",
    "similar_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artists similar to tag 'rock':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Marilyn Manson', 'U2', 'Demi Lovato', 'The Veronicas',\n",
       "       'Glee Cast', 'Pearl Jam', 'David Bowie', 'Adam Lambert',\n",
       "       'Nicole Scherzinger', 'Fall Out Boy'], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the names for similar atists\n",
    "artist_names = artists.set_index('id').loc[similar_artists.index]['name'].values\n",
    "\n",
    "# Get tag name\n",
    "tag_name = tags[tags['tagID'] == tag_id]['tagValue'].values[0]\n",
    "print(f\"Artists similar to tag '{tag_name}':\")\n",
    "artist_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested Tags for artist 221:\n",
      "['experimental', 'new wave', 'pop', 'dance', 'hip-hop', 'singer-songwriter', 'electronic', 'progressive rock', 'british', 'alternative rock']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "def suggest_similar_tags(idx, model, item_features, user_tags, tags, top_k=10, min_count=1000):\n",
    "    \"\"\"\n",
    "    Suggest similar tags for a chosen model index.\n",
    "\n",
    "    Args:\n",
    "    - idx: Index of the chosen model in the dataset.\n",
    "    - model: The trained LightFM model.\n",
    "    - item_features: Sparse matrix of item features.\n",
    "    - user_tags: DataFrame with user tags.\n",
    "    - tags: DataFrame with tagID and tagValue.\n",
    "    - top_k: Number of similar tags to suggest.\n",
    "    - min_count: Minimum count of tag occurrences to consider.\n",
    "\n",
    "    Returns:\n",
    "    - List of suggested tags.\n",
    "    \"\"\"\n",
    "    # Precompute tag frequency and filter\n",
    "    tag_counts = user_tags.groupby('tagID').size()\n",
    "    tag_counts = tag_counts[tag_counts >= min_count]\n",
    "    valid_tags = set(tag_counts.index)\n",
    "\n",
    "    # Map tagID to tagValue for fast lookup\n",
    "    tag_mapping = dict(zip(tags['tagID'], tags['tagValue']))\n",
    "\n",
    "    # Get tags already associated with the chosen model\n",
    "    filter_tags = set(item_features.getrow(idx).indices)\n",
    "\n",
    "    # Get the item's representation\n",
    "    item_representation = item_features.getrow(idx).dot(model.item_embeddings)\n",
    "\n",
    "    # Normalize item embeddings for cosine similarity\n",
    "    normalized_embeddings = model.item_embeddings / np.linalg.norm(model.item_embeddings, axis=1, keepdims=True)\n",
    "    sims = cosine_similarity(item_representation, normalized_embeddings).flatten()\n",
    "\n",
    "    # Sort indices by similarity (highest to lowest)\n",
    "    recs = np.argsort(-sims)\n",
    "\n",
    "    # Generate tag suggestions\n",
    "    suggested_tags = []\n",
    "    for offset_idx in recs:\n",
    "        if len(suggested_tags) >= top_k:\n",
    "            break\n",
    "        # Skip tags already associated with the model\n",
    "        if offset_idx in filter_tags:\n",
    "            continue\n",
    "        # Skip tags that don't meet the frequency threshold\n",
    "        if offset_idx not in valid_tags:\n",
    "            continue\n",
    "        # Append valid tag suggestions\n",
    "        if offset_idx in tag_mapping:\n",
    "            suggested_tags.append(tag_mapping[offset_idx])\n",
    "\n",
    "    return suggested_tags\n",
    "\n",
    "# Example Usage\n",
    "idx = 221  # Example model index\n",
    "suggested_tags = suggest_similar_tags(idx, model_features, item_features, user_tags, tags)\n",
    "\n",
    "# Display the results\n",
    "print(f'Suggested Tags for artist {idx}:')\n",
    "print(suggested_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
