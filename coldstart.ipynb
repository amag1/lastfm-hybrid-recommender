{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original length: 92834\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>artistID</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>13883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>11690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>11351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>10300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>8983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID  artistID  weight\n",
       "0       0        45   13883\n",
       "1       0        46   11690\n",
       "2       0        47   11351\n",
       "3       0        48   10300\n",
       "4       0        49    8983"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "artists = pd.read_csv('dataset/remapped/artists.csv')\n",
    "tags = pd.read_csv('dataset/remapped/tags.csv')\n",
    "user_artists = pd.read_csv('dataset/remapped/user_artists.csv')\n",
    "user_tags = pd.read_csv('dataset/remapped/user_tags.csv')\n",
    "\n",
    "print(f\"Original length: {len(user_artists)}\")\n",
    "user_artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12133, 9719)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Assuming user_tags, tags, and artists DataFrames are already loaded\n",
    "\n",
    "# Get the distribution of tags for each artist\n",
    "artist_tag_distribution = (\n",
    "    user_tags.groupby(['artistID', 'tagID'])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)  # Converts to wide format with tagIDs as columns\n",
    ")\n",
    "artist_tag_distribution.columns.name = None  # Remove column name for clarity\n",
    "artist_tag_distribution.reset_index(inplace=True)  # Make artistID a regular column\n",
    "\n",
    "artist_tag_distribution.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artistID</th>\n",
       "      <th>tagValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>weeabo jrock j-rock visual kei better than lad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>german seen live darkwave industrial german ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>black metal black metal norwegian black metal ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>j-rock visual kei metal gothic japanese bazaro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>gothic gothic rock darkwave darkwave deathrock...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artistID                                           tagValue\n",
       "0         0  weeabo jrock j-rock visual kei better than lad...\n",
       "1         1  german seen live darkwave industrial german ge...\n",
       "2         2  black metal black metal norwegian black metal ...\n",
       "3         3  j-rock visual kei metal gothic japanese bazaro...\n",
       "4         4  gothic gothic rock darkwave darkwave deathrock..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Build bag-of-words embeddings\n",
    "user_tags_with_values = user_tags.merge(tags, how='left', left_on='tagID', right_on='tagID')\n",
    "\n",
    "# Combine all tag values for each artist\n",
    "artist_bow = user_tags_with_values.groupby('artistID')['tagValue'].apply(\n",
    "    lambda x: ' '.join(map(str, x))\n",
    ").reset_index()\n",
    "\n",
    "\n",
    "artist_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding dimension: 7592\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Vectorize using CountVectorizer to build bag-of-words embeddings\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "bow_matrix = vectorizer.fit_transform(artist_bow['tagValue'])\n",
    "\n",
    "embedding_dim = len(vectorizer.get_feature_names_out())\n",
    "print(f\"Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12133, 7592)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df with embeddings\n",
    "artist_embeddings = pd.DataFrame.sparse.from_spmatrix(\n",
    "    bow_matrix, columns=vectorizer.get_feature_names_out(), index=artist_bow['artistID']\n",
    ")\n",
    "\n",
    "artist_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize rows in the embedding matrix\n",
    "artist_embeddings = artist_embeddings.div(artist_embeddings.sum(axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12133, 7592)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag distribution by artist:\n",
      "       artistID  0  1  2  3  4  5  6  7  8  ...  11935  11936  11937  11938  \\\n",
      "0             0  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "1             1  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "2             2  0  0  0  3  0  0  0  0  0  ...      0      0      0      0   \n",
      "3             3  2  0  0  0  0  0  1  0  0  ...      0      0      0      0   \n",
      "4             4  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "...         ... .. .. .. .. .. .. .. .. ..  ...    ...    ...    ...    ...   \n",
      "12128     17623  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "12129     17625  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "12130     17626  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "12131     17627  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "12132     17630  0  0  0  0  0  0  0  0  0  ...      0      0      0      0   \n",
      "\n",
      "       11939  11940  11941  11942  11943  11944  \n",
      "0          0      0      0      0      0      0  \n",
      "1          0      0      0      0      0      0  \n",
      "2          0      0      0      0      0      0  \n",
      "3          0      0      0      0      0      0  \n",
      "4          0      0      0      0      0      0  \n",
      "...      ...    ...    ...    ...    ...    ...  \n",
      "12128      0      0      0      0      0      0  \n",
      "12129      0      0      0      0      0      0  \n",
      "12130      0      0      0      0      0      0  \n",
      "12131      0      0      0      0      0      0  \n",
      "12132      0      0      0      0      0      0  \n",
      "\n",
      "[12133 rows x 9719 columns]\n",
      "\n",
      "Bag-of-Words Embeddings for artists:\n",
      "           00  007  00s   01   06   07   08   09   10  100  ...  zombie  \\\n",
      "artistID                                                    ...           \n",
      "0         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "1         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "2         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "3         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "4         0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...     ...   \n",
      "17623     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "17625     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "17626     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "17627     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "17630     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...     0.0   \n",
      "\n",
      "          zombieland  zone  zoocore  zooey  zorn  zornish  ztt   zu  ärzte  \n",
      "artistID                                                                    \n",
      "0                0.0   0.0      0.0    0.0   0.0      0.0  0.0  0.0    0.0  \n",
      "1                0.0   0.0      0.0    0.0   0.0      0.0  0.0  0.0    0.0  \n",
      "2                0.0   0.0      0.0    0.0   0.0      0.0  0.0  0.0    0.0  \n",
      "3                0.0   0.0      0.0    0.0   0.0      0.0  0.0  0.0    0.0  \n",
      "4                0.0   0.0      0.0    0.0   0.0      0.0  0.0  0.0    0.0  \n",
      "...              ...   ...      ...    ...   ...      ...  ...  ...    ...  \n",
      "17623            0.0   0.0      0.0    0.0   0.0      0.0  0.0  0.0    0.0  \n",
      "17625            0.0   0.0      0.0    0.0   0.0      0.0  0.0  0.0    0.0  \n",
      "17626            0.0   0.0      0.0    0.0   0.0      0.0  0.0  0.0    0.0  \n",
      "17627            0.0   0.0      0.0    0.0   0.0      0.0  0.0  0.0    0.0  \n",
      "17630            0.0   0.0      0.0    0.0   0.0      0.0  0.0  0.0    0.0  \n",
      "\n",
      "[12133 rows x 7592 columns]\n",
      "\n",
      "Sparse matrix shape (artist_count x embedding_dim): (17632, 7592)\n"
     ]
    }
   ],
   "source": [
    "# Build a sparse matrix of shape (artist_count, embedding_dim)\n",
    "# Ensure all artists have rows in the sparse matrix\n",
    "all_artists = artists[['id']].rename(columns={'id': 'artistID'})\n",
    "artist_embeddings_full = all_artists.merge(artist_embeddings, how='left', on='artistID').fillna(0)\n",
    "\n",
    "# Convert to sparse matrix\n",
    "embedding_sparse_matrix = csr_matrix(artist_embeddings_full.drop(columns=['artistID']).values)\n",
    "\n",
    "# Output results\n",
    "print(\"Tag distribution by artist:\")\n",
    "print(artist_tag_distribution)\n",
    "\n",
    "print(\"\\nBag-of-Words Embeddings for artists:\")\n",
    "print(artist_embeddings)\n",
    "\n",
    "print(\"\\nSparse matrix shape (artist_count x embedding_dim):\", embedding_sparse_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_name(artist_id):\n",
    "    return artists.loc[artists['id'] == artist_id, 'name'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar artists to artist 221:\n",
      "Artist: Michelle Williams, Similarity: 0.2019\n",
      "Artist: The Feeling, Similarity: 0.1059\n",
      "Artist: Plain White T's, Similarity: 0.0875\n",
      "Artist: The Cult, Similarity: 0.0792\n",
      "Artist: Crosby, Stills & Nash, Similarity: 0.0729\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_top_k_similar_artists(artist_id, embeddings, artist_index_map, k=5):\n",
    "    \"\"\"\n",
    "    Get the top K most similar artists to the given artist_id.\n",
    "\n",
    "    Parameters:\n",
    "    - artist_id (int): The ID of the artist to find similar artists for.\n",
    "    - embeddings (csr_matrix): The sparse matrix containing artist embeddings.\n",
    "    - artist_index_map (dict): A mapping of artist IDs to row indices in the embeddings matrix.\n",
    "    - k (int): The number of similar artists to return.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples: [(artist_id, similarity), ...] for the top K similar artists.\n",
    "    \"\"\"\n",
    "    # Ensure the artist ID is in the index map\n",
    "    if artist_id not in artist_index_map:\n",
    "        raise ValueError(f\"Artist ID {artist_id} not found in the embeddings.\")\n",
    "\n",
    "    # Get the index of the given artist\n",
    "    artist_idx = artist_index_map[artist_id]\n",
    "    \n",
    "    # Compute cosine similarity between the given artist and all others\n",
    "    artist_vector = embeddings[artist_idx]  # Sparse row for the given artist\n",
    "    similarities = cosine_similarity(artist_vector, embeddings).flatten()\n",
    "    \n",
    "    # Get the top K similar indices (excluding itself)\n",
    "    similar_indices = similarities.argsort()[::-1]  # Sort in descending order\n",
    "    top_k_indices = [idx for idx in similar_indices if idx != artist_idx][:k]\n",
    "    \n",
    "    # Map indices back to artist IDs and return their similarities\n",
    "    index_artist_map = {v: k for k, v in artist_index_map.items()}\n",
    "    top_k_artists = [(index_artist_map[idx], similarities[idx]) for idx in top_k_indices]\n",
    "\n",
    "    return top_k_artists\n",
    "\n",
    "# Create a mapping of artist IDs to their row indices in the embeddings matrix\n",
    "artist_index_map = {artist_id: idx for idx, artist_id in enumerate(artist_embeddings_full['artistID'])}\n",
    "\n",
    "example_artist_id = 221\n",
    "top_k_similar_artists = get_top_k_similar_artists(example_artist_id, embedding_sparse_matrix, artist_index_map, k=5)\n",
    "\n",
    "# Output results\n",
    "print(f\"Top similar artists to artist {example_artist_id}:\")\n",
    "for artist_id, similarity in top_k_similar_artists:\n",
    "    print(f\"Artist: {get_artist_name(artist_id)}, Similarity: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_name(tag_id):\n",
    "    return tags.loc[tags['tagID'] == tag_id, 'tagValue'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested tags for artist 221:\n",
      "Tag: indie, Score: 1.9109\n",
      "Tag: rock, Score: 1.7931\n",
      "Tag: alternative, Score: 1.4675\n",
      "Tag: pop, Score: 1.3513\n",
      "Tag: rnb, Score: 1.2117\n",
      "Tag: indie rock, Score: 0.9508\n",
      "Tag: soul, Score: 0.8078\n",
      "Tag: pop punk, Score: 0.7876\n",
      "Tag: female vocalists, Score: 0.7416\n",
      "Tag: acoustic, Score: 0.6742\n"
     ]
    }
   ],
   "source": [
    "def suggest_tags_for_artist(artist_id, embeddings, artist_index_map, artist_tag_distribution, tag_names, k=5, top_tags=5):\n",
    "    \"\"\"\n",
    "    Suggest tags for a given artist based on similar artists' tags.\n",
    "\n",
    "    Parameters:\n",
    "    - artist_id (int): The ID of the artist to suggest tags for.\n",
    "    - embeddings (csr_matrix): The sparse matrix containing artist embeddings.\n",
    "    - artist_index_map (dict): A mapping of artist IDs to row indices in the embeddings matrix.\n",
    "    - artist_tag_distribution (pd.DataFrame): Tag distribution (artist x tags).\n",
    "    - tag_names (pd.DataFrame): Mapping of tag IDs to tag names.\n",
    "    - k (int): Number of similar artists to consider for tag suggestions.\n",
    "    - top_tags (int): Number of tags to suggest.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples: [(tag_id, tag_name, relevance_score), ...] for the suggested tags.\n",
    "    \"\"\"\n",
    "    # Ensure the artist ID is in the index map\n",
    "    if artist_id not in artist_index_map:\n",
    "        raise ValueError(f\"Artist ID {artist_id} not found in the embeddings.\")\n",
    "    \n",
    "    # Get the top K similar artists\n",
    "    similar_artists = get_top_k_similar_artists(artist_id, embeddings, artist_index_map, k=k)\n",
    "    \n",
    "    # Aggregate tag frequencies from similar artists\n",
    "    tag_scores = pd.Series(dtype=float)\n",
    "    for similar_artist_id, similarity in similar_artists:\n",
    "        if similar_artist_id in artist_tag_distribution['artistID'].values:\n",
    "            similar_tags = artist_tag_distribution.loc[\n",
    "                artist_tag_distribution['artistID'] == similar_artist_id\n",
    "            ].drop(columns=['artistID']).iloc[0]\n",
    "            # Weighted score for tags based on similarity\n",
    "            tag_scores = tag_scores.add(similar_tags * similarity, fill_value=0)\n",
    "    \n",
    "    # Sort tags by their weighted scores\n",
    "    suggested_tags = tag_scores.sort_values(ascending=False).head(top_tags)\n",
    "    \n",
    "    return suggested_tags.items()\n",
    "\n",
    "suggested_tags = suggest_tags_for_artist(\n",
    "    example_artist_id, embedding_sparse_matrix, artist_index_map, artist_tag_distribution, tags, k=10, top_tags=10\n",
    ")\n",
    "\n",
    "# Output results\n",
    "print(f\"Suggested tags for artist {example_artist_id}:\")\n",
    "for tag_id, score in suggested_tags:\n",
    "    tag_name = get_tag_name(tag_id)\n",
    "    print(f\"Tag: {tag_name}, Score: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reduced_embeddings\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Reduce the embedding space to 200 dimensions\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m reduced_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mreduce_embedding_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding_sparse_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Example: Get reduced embedding for artist ID 2\u001b[39;00m\n\u001b[1;32m     31\u001b[0m artist_idx \u001b[38;5;241m=\u001b[39m artist_index_map[example_artist_id]\n",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m, in \u001b[0;36mreduce_embedding_dimension\u001b[0;34m(embeddings, target_dim)\u001b[0m\n\u001b[1;32m     15\u001b[0m svd \u001b[38;5;241m=\u001b[39m TruncatedSVD(n_components\u001b[38;5;241m=\u001b[39mtarget_dim, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Fit and transform the sparse matrix\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m reduced_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43msvd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Explained variance ratio to ensure the quality of reduction\u001b[39;00m\n\u001b[1;32m     21\u001b[0m explained_variance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(svd\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/_set_output.py:313\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 313\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    316\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    317\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    318\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    319\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/decomposition/_truncated_svd.py:246\u001b[0m, in \u001b[0;36mTruncatedSVD.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components \u001b[38;5;241m>\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    243\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be <=\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    244\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m n_features(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    245\u001b[0m         )\n\u001b[0;32m--> 246\u001b[0m     U, Sigma, VT \u001b[38;5;241m=\u001b[39m \u001b[43mrandomized_svd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_components\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_oversamples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_oversamples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpower_iteration_normalizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflip_sign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     U, VT \u001b[38;5;241m=\u001b[39m svd_flip(U, VT, u_based_decision\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcomponents_ \u001b[38;5;241m=\u001b[39m VT\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/sklearn/utils/extmath.py:539\u001b[0m, in \u001b[0;36mrandomized_svd\u001b[0;34m(M, n_components, n_oversamples, n_iter, power_iteration_normalizer, transpose, flip_sign, random_state, svd_lapack_driver)\u001b[0m\n\u001b[1;32m    534\u001b[0m     Uhat, s, Vt \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msvd(B, full_matrices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;66;03m# When when array_api_dispatch is disabled, rely on scipy.linalg\u001b[39;00m\n\u001b[1;32m    537\u001b[0m     \u001b[38;5;66;03m# instead of numpy.linalg to avoid introducing a behavior change w.r.t.\u001b[39;00m\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;66;03m# previous versions of scikit-learn.\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m     Uhat, s, Vt \u001b[38;5;241m=\u001b[39m \u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapack_driver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msvd_lapack_driver\u001b[49m\n\u001b[1;32m    541\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m B\n\u001b[1;32m    543\u001b[0m U \u001b[38;5;241m=\u001b[39m Q \u001b[38;5;241m@\u001b[39m Uhat\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/linalg/_decomp_svd.py:160\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    156\u001b[0m lwork \u001b[38;5;241m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], a1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m    157\u001b[0m                        compute_uv\u001b[38;5;241m=\u001b[39mcompute_uv, full_matrices\u001b[38;5;241m=\u001b[39mfull_matrices)\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# perform decomposition\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m u, s, v, info \u001b[38;5;241m=\u001b[39m \u001b[43mgesXd\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute_uv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_uv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlwork\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfull_matrices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverwrite_a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def reduce_embedding_dimension(embeddings, target_dim=200):\n",
    "    \"\"\"\n",
    "    Reduce the dimension of embeddings to a specified size using Truncated SVD.\n",
    "\n",
    "    Parameters:\n",
    "    - embeddings (csr_matrix): Sparse matrix of artist embeddings.\n",
    "    - target_dim (int): The desired number of dimensions for the reduced embeddings.\n",
    "\n",
    "    Returns:\n",
    "    - reduced_embeddings (np.ndarray): Dense array of reduced embeddings.\n",
    "    \"\"\"\n",
    "    # Initialize Truncated SVD\n",
    "    svd = TruncatedSVD(n_components=target_dim, random_state=42)\n",
    "    \n",
    "    # Fit and transform the sparse matrix\n",
    "    reduced_embeddings = svd.fit_transform(embeddings)\n",
    "    \n",
    "    # Explained variance ratio to ensure the quality of reduction\n",
    "    explained_variance = np.sum(svd.explained_variance_ratio_)\n",
    "    print(f\"Explained variance after reduction: {explained_variance:.4f}\")\n",
    "    \n",
    "    return reduced_embeddings\n",
    "\n",
    "\n",
    "# Reduce the embedding space to 200 dimensions\n",
    "reduced_embeddings = reduce_embedding_dimension(embedding_sparse_matrix, target_dim=200)\n",
    "\n",
    "# Example: Get reduced embedding for artist ID 2\n",
    "artist_idx = artist_index_map[example_artist_id]\n",
    "artist_reduced_embedding = reduced_embeddings[artist_idx]\n",
    "\n",
    "# Output results\n",
    "print(f\"Reduced embedding for artist ID {example_artist_id}:\")\n",
    "print(artist_reduced_embedding)\n",
    "print(f\"Shape of reduced embedding matrix: {reduced_embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse matrix shape: (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Create a sparse matrix for user-artist interactions\n",
    "user_artist_matrix = coo_matrix(\n",
    "    (user_artists['weight'], (user_artists['userID'], user_artists['artistID']))\n",
    ")\n",
    "\n",
    "# Output the shape of the matrix\n",
    "print(f\"Sparse matrix shape: {user_artist_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interactions matrix shape: (1892, 17632)\n"
     ]
    }
   ],
   "source": [
    "from lightfm.data import Dataset\n",
    "\n",
    "# Initialize the Dataset object\n",
    "dataset = Dataset(user_identity_features=False, item_identity_features=False)\n",
    "\n",
    "# Fit the dataset with users and items\n",
    "# Specify the number of users and items based on the user_artist_matrix\n",
    "num_users, num_artists = user_artist_matrix.shape\n",
    "dataset.fit(\n",
    "    range(num_users),  # User IDs\n",
    "    range(num_artists)  # Artist IDs\n",
    ")\n",
    "\n",
    "# Build interactions and weights matrices\n",
    "(interactions, weights) = dataset.build_interactions(\n",
    "    [(row['userID'], row['artistID'], row['weight']) for _, row in user_artists.iterrows()]\n",
    ")\n",
    "\n",
    "# Output the shape of the interactions matrix\n",
    "print(f\"Interactions matrix shape: {interactions.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training interactions: 74267\n",
      "Testing interactions: 18567\n"
     ]
    }
   ],
   "source": [
    "from lightfm.cross_validation import random_train_test_split\n",
    "\n",
    "# Split the interactions into training and testing datasets\n",
    "train, test = random_train_test_split(interactions, test_percentage=0.2, random_state=42)\n",
    "trainweighted, testweighted = random_train_test_split(weights, test_percentage=0.2, random_state=42)\n",
    "\n",
    "# Output the number of interactions in train and test\n",
    "print(f\"Training interactions: {train.getnnz()}\")\n",
    "print(f\"Testing interactions: {test.getnnz()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item features shape: (17632, 7592)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Ensure the embeddings have the same number of items as in the dataset\n",
    "item_features = csr_matrix(embedding_sparse_matrix)\n",
    "\n",
    "# Check the shape of the item_features\n",
    "print(f\"Item features shape: {item_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "\n",
    "# Initialize the LightFM model\n",
    "embedding_dim = embedding_sparse_matrix.shape[1]\n",
    "model = LightFM(no_components=20, loss='warp')\n",
    "\n",
    "# Train the model for one epoch\n",
    "model.fit(train, item_features=item_features, epochs=10, num_threads=4)\n",
    "\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train AUC: 0.8843\n",
      "Test AUC: 0.8550\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Evaluate performance\n",
    "from lightfm.evaluation import auc_score\n",
    "\n",
    "# Compute and print the AUC score\n",
    "train_auc = auc_score(model, train, item_features=item_features, num_threads=4).mean()\n",
    "test_auc = auc_score(model, test, item_features=item_features, num_threads=4).mean()\n",
    "\n",
    "print(f\"Train AUC: {train_auc:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get embeddings from the trained model\n",
    "item_biases, item_embeddings = model.get_item_representations(features=item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get similar artists as above using resulting embeddings\n",
    "def get_top_k_similar_artists_lightfm(model, artist_id, k=5):\n",
    "    \"\"\"\n",
    "    Get the top K most similar artists to the given artist_id using the LightFM model.\n",
    "\n",
    "    Parameters:\n",
    "    - model (LightFM): The trained LightFM model.\n",
    "    - artist_id (int): The ID of the artist to find similar artists for.\n",
    "    - k (int): The number of similar artists to return.\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples: [(artist_id, similarity), ...] for the top K similar artists.\n",
    "    \"\"\"\n",
    "    # Get the index of the given artist\n",
    "    artist_idx = artist_index_map[artist_id]\n",
    "    \n",
    "    # Compute artist embeddings\n",
    "    artist_embedding = model.get_item_representations(features=item_features)[1]\n",
    "    print(artist_embedding.shape)\n",
    "    \n",
    "    # Compute cosine similarity between the given artist and all others\n",
    "    similarities = cosine_similarity([artist_embedding[artist_idx]], artist_embedding).flatten()\n",
    "    # Get the top K similar indices (excluding itself)\n",
    "    similar_indices = similarities.argsort()[::-1]  # Sort in descending order\n",
    "    top_k_indices = [idx for idx in similar_indices if idx != artist_idx][:k]\n",
    "\n",
    "    # Map indices back to artist IDs and return their similarities\n",
    "    index_artist_map = {v: k for k, v in artist_index_map.items()}\n",
    "    top_k_artists = [(index_artist_map[idx], similarities[idx]) for idx in top_k_indices]\n",
    "\n",
    "\n",
    "    return top_k_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17632, 20)\n",
      "[ 0.31058118 -0.07600567 -0.45401764 ...  0.         -0.11866216\n",
      "  0.        ] [1405, 727, 1795, 505, 593]\n",
      "0.9812064\n",
      "[(1405, 0.9812064), (727, 0.9771702), (1795, 0.9683263), (505, 0.96734214), (593, 0.95420647)]\n"
     ]
    }
   ],
   "source": [
    "similar = get_top_k_similar_artists_lightfm(model, example_artist_id, k=5)\n",
    "print(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar artists to artist 221:\n",
      "['Paul McCartney', 'John Lennon', 'T. Rex', 'U2', 'David Bowie']\n"
     ]
    }
   ],
   "source": [
    "similarNames = [get_artist_name(artist_id) for artist_id, _ in similar]\n",
    "similarScores = [score for _, score in similar]\n",
    "\n",
    "# Output results\n",
    "print(f\"Top similar artists to artist {example_artist_id}:\")\n",
    "print(similarNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tag_id_by_name(tag_name):\n",
    "    return tags.loc[tags['tagValue'] == tag_name, 'tagID'].values[0]\n",
    "\n",
    "def get_cold_start_similar_artists(model,item_tags, importance_schema='equal'):\n",
    "    importance_weights = []\n",
    "    try:\n",
    "        item_tag_ids = [get_tag_id_by_name(tag) for tag in item_tags]\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Tag not found: {e}\")\n",
    "    \n",
    "    if importance_schema == 'equal':\n",
    "        importance_weights = np.ones(shape=len(item_tags))\n",
    "    elif importance_schema == 'scaled':\n",
    "        importance_weights = [len(item_tags) - i for i in range(len(item_tags))]\n",
    "    else:\n",
    "        raise ValueError(f'schema not found: {importance_schema}')\n",
    "\n",
    "    normalized_weights = [weight / sum(importance_weights) for weight in importance_weights]\n",
    "\n",
    "    new_embedding = np.zeros(shape=embedding_dim)\n",
    "    for tag_id, weight in zip(item_tag_ids, normalized_weights):\n",
    "        new_embedding[tag_id] = weight\n",
    "\n",
    "    new_item_sparse = csr_matrix(new_embedding)\n",
    "\n",
    "    cold_bias, cold_embedding = model.get_item_representations(new_item_sparse)\n",
    "    sim = pd.DataFrame(cosine_similarity(cold_embedding, item_embeddings).T, columns=([\"cosine\"]))\n",
    "    \n",
    "    sim = sim.sort_values(by=\"cosine\", ascending=False).head(5)\n",
    "\n",
    "    # Add the artist names to the DataFrame\n",
    "    sim['artistID'] = sim.index\n",
    "    sim['artistName'] = sim['artistID'].apply(get_artist_name)\n",
    "\n",
    "    return sim\n",
    "\n",
    "# new_item_tags = ['rock', 'punk', 'alternative']\n",
    "# similar_cold_start = get_cold_start_similar_artists(model, new_item_tags, importance_schema='scaled')\n",
    "# print(similar_cold_start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the last model to make predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('final_model.pkl', 'rb') as f:\n",
    "    model_loaded = pickle.load(f)\n",
    "\n",
    "item_biases, item_embeddings = model_loaded.get_item_representations(features=item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[72, 379, 78, 180]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_item_tags = ['rock', 'heavy metal', 'alternative', 'punk']\n",
    "weights = [1000, 1000, 1000,1000]\n",
    "\n",
    "importance_weights = [len(new_item_tags) - i for i in range(len(new_item_tags))]\n",
    "\n",
    "new_item_tag_ids = [get_tag_id_by_name(tag) for tag in new_item_tags]\n",
    "new_item_tag_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1340662287169862, 0.9033423667570009, 0.19146084625694046, 0.7763975155279503]\n"
     ]
    }
   ],
   "source": [
    "# For each weights, divide them by the total number of tags for that tag\n",
    "def normalize_weights(item_tag_ids, weights):\n",
    "    normalized_weights = []\n",
    "    for tag_id, weight in zip(item_tag_ids, weights):\n",
    "        # Get the number of usages for the tag\n",
    "        tag_usage = artist_tag_distribution[tag_id].sum()\n",
    "        # Normalize the weight by the tag usage\n",
    "        normalized_weight = weight / tag_usage\n",
    "\n",
    "        normalized_weights.append(normalized_weight)\n",
    "\n",
    "    return normalized_weights\n",
    "\n",
    "normalized_weights = normalize_weights(new_item_tag_ids, weights)\n",
    "print(normalized_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedding for the new item with weighted tags\n",
    "new_item = np.zeros((1, embedding_dim))\n",
    "for tag_id, weight in zip(new_item_tag_ids, normalized_weights):\n",
    "    new_item[0, tag_id] = weight\n",
    "\n",
    "assert new_item.shape[1] == embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.06294477 -0.16739881 -0.11776397  0.14600271  0.11476924 -0.02729657\n",
      "  -0.14526105 -0.08363269 -0.05568342 -0.27797174 -0.01127989 -0.14961001\n",
      "   0.1715923   0.03403715 -0.20238072 -0.08770192  0.15465051 -0.01443395\n",
      "  -0.03223583 -0.02824494  0.05564625 -0.0503132  -0.0274598  -0.13913724\n",
      "   0.14067441 -0.00588262 -0.03046503 -0.09196687  0.01727792  0.14257266\n",
      "   0.04179351  0.08114272  0.15406035  0.18801716 -0.08903887 -0.04362652\n",
      "  -0.1014284  -0.17313752 -0.07663249 -0.1977252  -0.05465395  0.13367885\n",
      "  -0.13094248  0.21019554  0.09908233  0.01885449  0.10650495  0.15686612\n",
      "  -0.17888841 -0.19587642 -0.16458768  0.071889   -0.02217916 -0.09075703\n",
      "  -0.03437797  0.06406043 -0.17064948 -0.11219095 -0.05757154  0.04213144\n",
      "  -0.04611449 -0.00094899 -0.03252514 -0.02964789]]\n"
     ]
    }
   ],
   "source": [
    "# convert t to a sparse matrix\n",
    "new_item_sparse = csr_matrix(new_item)\n",
    "\n",
    "cold_bias, cold_embedding = model_loaded.get_item_representations(new_item_sparse)\n",
    "\n",
    "print(cold_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = pd.DataFrame(cosine_similarity(cold_embedding, item_embeddings).T, columns=([\"cosine\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "      <th>artistID</th>\n",
       "      <th>artistName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13543</th>\n",
       "      <td>0.935041</td>\n",
       "      <td>13543</td>\n",
       "      <td>Норд-Ост</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11661</th>\n",
       "      <td>0.918789</td>\n",
       "      <td>11661</td>\n",
       "      <td>Robin Trower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0.917022</td>\n",
       "      <td>587</td>\n",
       "      <td>Renato Carosone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9674</th>\n",
       "      <td>0.911273</td>\n",
       "      <td>9674</td>\n",
       "      <td>Monkey3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8428</th>\n",
       "      <td>0.909505</td>\n",
       "      <td>8428</td>\n",
       "      <td>Владимир Высоцкий</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cosine  artistID         artistName\n",
       "13543  0.935041     13543           Норд-Ост\n",
       "11661  0.918789     11661       Robin Trower\n",
       "587    0.917022       587    Renato Carosone\n",
       "9674   0.911273      9674            Monkey3\n",
       "8428   0.909505      8428  Владимир Высоцкий"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = sim.sort_values(by=\"cosine\", ascending=False).head(5)\n",
    "\n",
    "# Add the artist names to the DataFrame\n",
    "sim['artistID'] = sim.index\n",
    "sim['artistName'] = sim['artistID'].apply(get_artist_name)\n",
    "\n",
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cosine</th>\n",
       "      <th>artistID</th>\n",
       "      <th>artistName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9029</th>\n",
       "      <td>0.985669</td>\n",
       "      <td>9029</td>\n",
       "      <td>Gavin Rossdale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>0.985248</td>\n",
       "      <td>1379</td>\n",
       "      <td>Gary Jules</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6312</th>\n",
       "      <td>0.984765</td>\n",
       "      <td>6312</td>\n",
       "      <td>Anna Nalick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10377</th>\n",
       "      <td>0.984553</td>\n",
       "      <td>10377</td>\n",
       "      <td>Alex Band</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4610</th>\n",
       "      <td>0.984135</td>\n",
       "      <td>4610</td>\n",
       "      <td>Vanessa da Mata</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cosine  artistID       artistName\n",
       "9029   0.985669      9029   Gavin Rossdale\n",
       "1379   0.985248      1379       Gary Jules\n",
       "6312   0.984765      6312      Anna Nalick\n",
       "10377  0.984553     10377        Alex Band\n",
       "4610   0.984135      4610  Vanessa da Mata"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cold_start_similar_artists(model_loaded, new_item_tags)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
