{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(92834, 3) (186479, 6)\n",
      "(92834, 3) (184941, 6)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets (replace with actual file paths or DataFrame initialization)\n",
    "artists = pd.read_csv('dataset/artists.dat', sep='\\t')\n",
    "tags = pd.read_csv('dataset/tags.dat', sep='\\t', encoding='ISO-8859-1')\n",
    "user_artists = pd.read_csv('dataset/user_artists.dat', sep='\\t')\n",
    "user_tags = pd.read_csv('dataset/user_taggedartists.dat', sep='\\t')\n",
    "\n",
    "print(user_artists.shape, user_tags.shape)\n",
    "# Step 1: Remove interactions with invalid artistIDs\n",
    "valid_artist_ids = set(artists['id'])\n",
    "user_artists = user_artists[user_artists['artistID'].isin(valid_artist_ids)]\n",
    "user_tags = user_tags[user_tags['artistID'].isin(valid_artist_ids)]\n",
    "\n",
    "# Step 2: Remove interactions with invalid tagIDs\n",
    "valid_tag_ids = set(tags['tagID'])\n",
    "user_tags = user_tags[user_tags['tagID'].isin(valid_tag_ids)]\n",
    "\n",
    "print(user_artists.shape, user_tags.shape)\n",
    "# Step 3: Save or return cleaned data\n",
    "user_artists.to_csv(\"dataset/cleaned_user_artists.csv\", index=False)\n",
    "user_tags.to_csv(\"dataset/cleaned_user_tags.csv\", index=False)\n",
    "\n",
    "# Only a few rows were removed, so the data is already quite clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist ID Analysis:\n",
      " - Min ID: 0\n",
      " - Max ID: 17631\n",
      " - Total Unique IDs: 17632\n",
      " - Number of Gaps in the Range: 0\n",
      "User-Artist (Artist ID) ID Analysis:\n",
      " - Min ID: 0\n",
      " - Max ID: 17631\n",
      " - Total Unique IDs: 17632\n",
      " - Number of Gaps in the Range: 0\n",
      "User-Tag (Artist ID) ID Analysis:\n",
      " - Min ID: 0\n",
      " - Max ID: 17630\n",
      " - Total Unique IDs: 17632\n",
      " - Number of Gaps in the Range: 5498\n",
      "Tag ID Analysis:\n",
      " - Min ID: 0\n",
      " - Max ID: 11945\n",
      " - Total Unique IDs: 11946\n",
      " - Number of Gaps in the Range: 0\n",
      "User-Tag (Tag ID) ID Analysis:\n",
      " - Min ID: 0\n",
      " - Max ID: 11944\n",
      " - Total Unique IDs: 11946\n",
      " - Number of Gaps in the Range: 2227\n",
      "User-Artist (User ID) ID Analysis:\n",
      " - Min ID: 0\n",
      " - Max ID: 1891\n",
      " - Total Unique IDs: 1892\n",
      " - Number of Gaps in the Range: 0\n",
      "User-Tag (User ID) ID Analysis:\n",
      " - Min ID: 0\n",
      " - Max ID: 1891\n",
      " - Total Unique IDs: 1892\n",
      " - Number of Gaps in the Range: 1\n",
      "Artist mapping is correct and consistent.\n",
      "User-Artist (Artist ID) mapping is correct and consistent.\n",
      "User-Tag (Artist ID) mapping is correct and consistent.\n",
      "Tag mapping is correct and consistent.\n",
      "User-Tag (Tag ID) mapping is correct and consistent.\n",
      "User-Artist (User ID) mapping is correct and consistent.\n",
      "User-Tag (User ID) mapping is correct and consistent.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the remapping function with consistent mappings\n",
    "def analyze_and_remap_ids(df, column, id_name, existing_mapping=None):\n",
    "    # Get unique IDs\n",
    "    unique_ids = df[column].unique()\n",
    "    \n",
    "    # Create a new mapping if one doesn't exist\n",
    "    if existing_mapping is None:\n",
    "        sorted_ids = sorted(unique_ids)\n",
    "        mapping = {old_id: new_id for new_id, old_id in enumerate(sorted_ids)}\n",
    "    else:\n",
    "        mapping = existing_mapping  # Use the provided mapping\n",
    "    \n",
    "    # Apply the mapping to the DataFrame\n",
    "    df[column] = df[column].map(mapping)\n",
    "    \n",
    "    # Print analysis\n",
    "    min_id = df[column].min()\n",
    "    max_id = df[column].max()\n",
    "    total_ids = len(mapping)\n",
    "    gaps = len(set(range(min_id, max_id + 1)) - set(df[column].unique()))\n",
    "    print(f\"{id_name} ID Analysis:\")\n",
    "    print(f\" - Min ID: {min_id}\")\n",
    "    print(f\" - Max ID: {max_id}\")\n",
    "    print(f\" - Total Unique IDs: {total_ids}\")\n",
    "    print(f\" - Number of Gaps in the Range: {gaps}\")\n",
    "    \n",
    "    return df, mapping\n",
    "\n",
    "def verify_mapping_consistency(df, column, mapping, id_name):\n",
    "    # Check if all values in the column map to the expected range\n",
    "    mapped_ids = df[column].unique()\n",
    "    expected_ids = set(range(len(mapping)))\n",
    "    \n",
    "    # Check for unexpected IDs\n",
    "    if not set(mapped_ids).issubset(expected_ids):\n",
    "        print(f\"Error: {id_name} contains IDs outside the expected range!\")\n",
    "        print(f\"Unexpected IDs: {set(mapped_ids) - expected_ids}\")\n",
    "        return False\n",
    "    \n",
    "    # Check that the mapping is bijective\n",
    "    if len(mapping) != len(set(mapping.values())):\n",
    "        print(f\"Error: {id_name} mapping is not bijective!\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"{id_name} mapping is correct and consistent.\")\n",
    "    return True\n",
    "\n",
    "# Step 2: Remap artist IDs consistently across datasets\n",
    "artists, artist_id_mapping = analyze_and_remap_ids(artists, \"id\", \"Artist\")\n",
    "user_artists, _ = analyze_and_remap_ids(user_artists, \"artistID\", \"User-Artist (Artist ID)\", artist_id_mapping)\n",
    "user_tags, _ = analyze_and_remap_ids(user_tags, \"artistID\", \"User-Tag (Artist ID)\", artist_id_mapping)\n",
    "\n",
    "# Step 3: Remap tag IDs consistently across datasets\n",
    "tags, tag_id_mapping = analyze_and_remap_ids(tags, \"tagID\", \"Tag\")\n",
    "user_tags, _ = analyze_and_remap_ids(user_tags, \"tagID\", \"User-Tag (Tag ID)\", tag_id_mapping)\n",
    "\n",
    "# Step 4: Remap user IDs consistently across datasets\n",
    "user_artists, user_id_mapping = analyze_and_remap_ids(user_artists, \"userID\", \"User-Artist (User ID)\")\n",
    "user_tags, _ = analyze_and_remap_ids(user_tags, \"userID\", \"User-Tag (User ID)\", user_id_mapping)\n",
    "\n",
    "# Step 6: Validate mappings\n",
    "assert(verify_mapping_consistency(artists, \"id\", artist_id_mapping, \"Artist\"))\n",
    "assert(verify_mapping_consistency(user_artists, \"artistID\", artist_id_mapping, \"User-Artist (Artist ID)\"))\n",
    "assert(verify_mapping_consistency(user_tags, \"artistID\", artist_id_mapping, \"User-Tag (Artist ID)\"))\n",
    "\n",
    "assert(verify_mapping_consistency(tags, \"tagID\", tag_id_mapping, \"Tag\"))\n",
    "assert(verify_mapping_consistency(user_tags, \"tagID\", tag_id_mapping, \"User-Tag (Tag ID)\"))\n",
    "\n",
    "assert(verify_mapping_consistency(user_artists, \"userID\", user_id_mapping, \"User-Artist (User ID)\"))\n",
    "assert(verify_mapping_consistency(user_tags, \"userID\", user_id_mapping, \"User-Tag (User ID)\"))\n",
    "\n",
    "artists.to_csv(\"dataset/remapped/artists.csv\", index=False)\n",
    "tags.to_csv(\"dataset/remapped/tags.csv\", index=False)\n",
    "user_artists.to_csv(\"dataset/remapped/user_artists.csv\", index=False)\n",
    "user_tags.to_csv(\"dataset/remapped/user_tags.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
